{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Recommendation Systems with Apache MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation systems are known for providing amazing experiences across any industry and user base. This notebook walks through building a content-based recommendation system using Scikit-Learn and MXNet.\n",
    "\n",
    "This recommendation system will request the top N recommended news articles, relative to the content of each news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pprint import pprint\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessText:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.additional_stop_words = {\"-PRON-\"}\n",
    "        self.stop_words = set(STOP_WORDS.union(self.additional_stop_words))\n",
    "\n",
    "    def lemmatization(self, texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "        \"\"\"\n",
    "        Tokenize and lemmatize all documents. The following criteria are used to evaluate each word.\n",
    "            Is the token a stop word?\n",
    "            Is the token comprised of letters?\n",
    "            Is the token longer than 1 letter?\n",
    "            Is the token an allowed POS tag?\n",
    "            Is the lemmatized token a stop word?\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"Lemmatizing Text\")\n",
    "\n",
    "        # Initialize spaCy\n",
    "        nlp = spacy.load('en_core_web_md', disable=[\"parser\", \"ner\"])\n",
    "\n",
    "        texts_out = []\n",
    "\n",
    "        for text in texts:\n",
    "            doc = nlp(text)\n",
    "            texts_out.append([token.lemma_ for token in doc\n",
    "                              if not token.is_stop\n",
    "                              and token.lemma_ not in self.stop_words\n",
    "                              and token.is_alpha\n",
    "                              and len(token) > 1\n",
    "                              and token.pos_ in allowed_postags])\n",
    "\n",
    "            if len(texts_out) % 1000 == 0:\n",
    "                print(\"Lemmatized {0} of {1} documents\".format(\n",
    "                    len(texts_out), len(texts)))\n",
    "\n",
    "        return texts_out\n",
    "\n",
    "\n",
    "def extract_features(f):\n",
    "    return pd.read_csv(f, usecols=[\"id\", \"title\", \"publication\", \"content\"])\n",
    "\n",
    "\n",
    "def get_recommendations(df_articles, article_idx, mx_mat, n_recs=10):\n",
    "    \"\"\"\n",
    "    Request top N article recommendations.\n",
    "\n",
    "    INPUT\n",
    "        df_articles: Pandas DataFrame containing all articles.\n",
    "        user_id: User ID being provided matches.\n",
    "        mx_mat: MXNet cosine similarity matrix\n",
    "    OUTPUT\n",
    "        Pandas DataFrame of top N article recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Similarity and recommendations\n",
    "    article_sims = mx_mat[article_idx].asnumpy()\n",
    "    article_recs = np.argsort(-article_sims).tolist()[:n_recs + 1]\n",
    "\n",
    "    # Top recommendations\n",
    "    df_recs = df_articles.iloc[article_recs]\n",
    "    df_recs[\"similarity\"] = article_sims[article_recs]\n",
    "\n",
    "    return df_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Article Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the file path to the article files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/\"\n",
    "all_files = glob.glob(file_path + \"*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all articles with Pandas, using the `extract_files` function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features across all files into a single data frame.\n",
    "articles = pd.concat((extract_features(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the files, subset the first 1000 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF is designed to reduce the number of tokens occurring within the corpus. When the TF-IDF Vectorizer is utilized, a vocabulary is created from the entire set of news articles, also referred to as \"documents\".\n",
    "\n",
    "After importing the documents, define the TfidfVectorizer from Scikit-Learn, and run against the content of all the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer=\"word\",\n",
    "                    ngram_range=(1, 3),\n",
    "                    min_df=0.2, # ignore terms with a document frequency lower than 0.2 (20%)\n",
    "                    stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tf.fit_transform(articles[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `tfidf_matrix` to an MXNet NDArray, and perform the same dot product operation. Just like the TfidfVectorizer, `mx.nd.sparse.array` creates a sparse matrix, where the majority of the elements in the matrix are zero.\n",
    "\n",
    "The `ctx` parameter specifies the context of where the data should reside. The context can be set to `mx.cpu()` for the DRAM & CPU, or `mx.gpu()` for the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_tfidf = mx.nd.sparse.array(tfidf_matrix, ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product Timing: NumPy vs MXNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the dot product with NumPy and Scikit-Learn sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.2 ms ± 7.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.dot(tfidf_matrix, tfidf_matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the dot product of the MXNet sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7 ms ± 537 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mx.nd.sparse.dot(mx_tfidf, mx_tfidf.T)\n",
    "mx.nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Time the dot product of the MXNet sparse matrix on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_tfidf = mx.nd.sparse.array(tfidf_matrix, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.46 ms ± 278 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mx.nd.sparse.dot(mx_tfidf, mx_tfidf.T)\n",
    "mx.nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Speed of NumPy vs MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot product is 80% faster than NumPy on CPU.\n",
      "The dot product is 93% faster than NumPy on GPU.\n"
     ]
    }
   ],
   "source": [
    "numpy_time = 34.2\n",
    "mxnet_time_cpu = 6.7\n",
    "mxnet_time_gpu = 2.46\n",
    "\n",
    "mxnet_speedup_cpu = (1 - (mxnet_time_cpu / numpy_time)) * 100\n",
    "mxnet_speedup_gpu = (1 - (mxnet_time_gpu / numpy_time)) * 100\n",
    "\n",
    "\n",
    "print(\"The dot product is {}% faster than NumPy on CPU.\".format(round(mxnet_speedup_cpu)))\n",
    "print(\"The dot product is {}% faster than NumPy on GPU.\".format(round(mxnet_speedup_gpu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_recsys = mx.nd.sparse.dot(mx_tfidf, mx_tfidf.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Recommendations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 recommendations from the article at index 3. Feel free to select any index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_recs = get_recommendations(df_articles = articles,\n",
    "    article_idx = 3, mx_mat = mx_recsys, n_recs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the recommendations in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feared my life lacked meaning. Cancer pushed...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Chuck (aka The Bleeder) review - Liev Schreibe...</td>\n",
       "      <td>0.544347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Thom Yorke’s ex-partner Rachel Owen dies at 48</td>\n",
       "      <td>0.504341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Mr Robot returns and The Girlfriend Experience...</td>\n",
       "      <td>0.500740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>My nieces don’t know they were conceived by do...</td>\n",
       "      <td>0.482433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Bridget Jones: how to turn a female character ...</td>\n",
       "      <td>0.482205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Robert Rauschenberg and the subversive languag...</td>\n",
       "      <td>0.476691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zsa Zsa Gabor dies aged 99</td>\n",
       "      <td>0.476189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>The rise of K2: the drug is legal, dangerous –...</td>\n",
       "      <td>0.469531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Facebook is chipping away at privacy – and my ...</td>\n",
       "      <td>0.464698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pokémon Go: five tricks for pro players that a...</td>\n",
       "      <td>0.458030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  similarity\n",
       "3    I feared my life lacked meaning. Cancer pushed...    1.000000\n",
       "167  Chuck (aka The Bleeder) review - Liev Schreibe...    0.544347\n",
       "726     Thom Yorke’s ex-partner Rachel Owen dies at 48    0.504341\n",
       "373  Mr Robot returns and The Girlfriend Experience...    0.500740\n",
       "764  My nieces don’t know they were conceived by do...    0.482433\n",
       "563  Bridget Jones: how to turn a female character ...    0.482205\n",
       "216  Robert Rauschenberg and the subversive languag...    0.476691\n",
       "96                          Zsa Zsa Gabor dies aged 99    0.476189\n",
       "678  The rise of K2: the drug is legal, dangerous –...    0.469531\n",
       "765  Facebook is chipping away at privacy – and my ...    0.464698\n",
       "21   Pokémon Go: five tricks for pro players that a...    0.458030"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recs[[\"title\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
