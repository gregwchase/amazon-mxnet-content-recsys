{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommendation System with MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/greg/.local/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import glob\n",
    "import gensim\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessText():\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.additional_stop_words = {\"-PRON-\"}\n",
    "\t\tself.stop_words = set(STOP_WORDS.union(self.additional_stop_words))\n",
    "\n",
    "\tdef make_bigrams(self, texts):\n",
    "\t\t\"\"\"\n",
    "\t\tCreate bigrams from documents.\n",
    "\t\tHigher thresholds yield fewer phrases\n",
    "\t\t\"\"\"\n",
    "\t\tbigram = gensim.models.Phrases(texts, min_count=2, threshold=10)\n",
    "\t\tbigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\t\treturn [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "\tdef lemmatization(self, texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "\t\t\"\"\"\n",
    "\t\tTokenize and lemmatize all documents. The following criteria are used to evaluate each word.\n",
    "\t\t\t\tIs the token a stop word?\n",
    "\t\t\t\tIs the token comprised of letters?\n",
    "\t\t\t\tIs the token longer than 1 letter?\n",
    "\t\t\t\tIs the token an allowed POS tag?\n",
    "\t\t\t\tIs the lemmatized token a stop word?\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"Lemmatizing Text\")\n",
    "\n",
    "\t\t# Initialize spaCy\n",
    "\t\tnlp = spacy.load('en_core_web_md', disable=[\"parser\", \"ner\"])\n",
    "\n",
    "\t\ttexts_out = []\n",
    "\n",
    "\t\tfor text in texts:\n",
    "\t\t\tdoc = nlp(text)\n",
    "\t\t\ttexts_out.append([token.lemma_ for token in doc\n",
    "\t\t\t\t\t\t\t  if not token.is_stop\n",
    "\t\t\t\t\t\t\t  and token.lemma_ not in self.stop_words\n",
    "\t\t\t\t\t\t\t  and token.is_alpha\n",
    "\t\t\t\t\t\t\t  and len(token) > 1\n",
    "\t\t\t\t\t\t\t  and token.pos_ in allowed_postags])\n",
    "\n",
    "\t\t\tif len(texts_out) % 1000 == 0:\n",
    "\t\t\t\tprint(\"Lemmatized {0} of {1} documents\".format(\n",
    "\t\t\t\t\tlen(texts_out), len(texts)))\n",
    "\n",
    "\t\treturn texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the file path to the article files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/\"\n",
    "all_files = glob.glob(file_path + \"*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all articles with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = lambda f : pd.read_csv(f, usecols = [\"id\", \"title\", \"publication\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features across all files into a single data frame.\n",
    "articles = pd.concat((extract_features(f) for f in all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first 1000 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the TF-IDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer=\"word\",\n",
    "                    ngram_range=(1, 3),\n",
    "                    min_df=0.2, # ignore terms with a document frequency lower than 0.2 (20%)\n",
    "                    stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tf.fit_transform(articles[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `tfidf_matrix` to an MXNet NDArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_tfidf = mx.nd.sparse.array(tfidf_matrix, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product Timing: NumPy vs MXNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the dot product with NumPy and Scikit-Learn sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.5 ms ± 150 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.dot(tfidf_matrix, tfidf_matrix.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time the dot product of the MXNet sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63 ms ± 9.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mx.nd.sparse.dot(mx_tfidf, mx_tfidf.T)\n",
    "mx.nd.waitall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the dot product, and create the cosine similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_recsys = mx.nd.sparse.dot(mx_tfidf, mx_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df_articles, article_idx, mx_mat, n_recs=10):\n",
    "    \"\"\"\n",
    "    Request top N article recommendations.\n",
    "\n",
    "    INPUT\n",
    "        df_articles: Pandas DataFrame containing all articles.\n",
    "        user_id: User ID being provided matches.\n",
    "        mx_mat: MXNet cosine similarity matrix\n",
    "    OUTPUT\n",
    "        Pandas DataFrame of top N article recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    article_sims = mx_mat[article_idx].asnumpy()\n",
    "    article_recs = np.argsort(-article_sims)[:n_recs + 1]\n",
    "\n",
    "    # Top recommendations\n",
    "    df_recs = df_articles.loc[list(article_recs)]\n",
    "    df_recs[\"similarity\"] = article_sims[article_recs]\n",
    "\n",
    "    return df_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 recommendations from the article at index 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recs = get_recommendations(df_articles = articles,\n",
    "    article_idx = 3, mx_mat = mx_recsys, n_recs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the recommendations in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feared my life lacked meaning. Cancer pushed...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Chuck (aka The Bleeder) review - Liev Schreibe...</td>\n",
       "      <td>0.544347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Thom Yorke’s ex-partner Rachel Owen dies at 48</td>\n",
       "      <td>0.504341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Mr Robot returns and The Girlfriend Experience...</td>\n",
       "      <td>0.500740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>My nieces don’t know they were conceived by do...</td>\n",
       "      <td>0.482433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Bridget Jones: how to turn a female character ...</td>\n",
       "      <td>0.482205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Robert Rauschenberg and the subversive languag...</td>\n",
       "      <td>0.476691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Zsa Zsa Gabor dies aged 99</td>\n",
       "      <td>0.476189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>The rise of K2: the drug is legal, dangerous –...</td>\n",
       "      <td>0.469531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>Facebook is chipping away at privacy – and my ...</td>\n",
       "      <td>0.464698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pokémon Go: five tricks for pro players that a...</td>\n",
       "      <td>0.458030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  similarity\n",
       "3    I feared my life lacked meaning. Cancer pushed...    1.000000\n",
       "167  Chuck (aka The Bleeder) review - Liev Schreibe...    0.544347\n",
       "726     Thom Yorke’s ex-partner Rachel Owen dies at 48    0.504341\n",
       "373  Mr Robot returns and The Girlfriend Experience...    0.500740\n",
       "764  My nieces don’t know they were conceived by do...    0.482433\n",
       "563  Bridget Jones: how to turn a female character ...    0.482205\n",
       "216  Robert Rauschenberg and the subversive languag...    0.476691\n",
       "96                          Zsa Zsa Gabor dies aged 99    0.476189\n",
       "678  The rise of K2: the drug is legal, dangerous –...    0.469531\n",
       "765  Facebook is chipping away at privacy – and my ...    0.464698\n",
       "21   Pokémon Go: five tricks for pro players that a...    0.458030"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recs[[\"title\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
