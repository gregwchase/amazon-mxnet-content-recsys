{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based Recommendation System with MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/greg/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/greg/.local/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import glob\n",
    "import gensim\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessText():\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.additional_stop_words = {\"-PRON-\"}\n",
    "\t\tself.stop_words = set(STOP_WORDS.union(self.additional_stop_words))\n",
    "\n",
    "\tdef make_bigrams(self, texts):\n",
    "\t\t\"\"\"\n",
    "\t\tCreate bigrams from documents.\n",
    "\t\tHigher thresholds yield fewer phrases\n",
    "\t\t\"\"\"\n",
    "\t\tbigram = gensim.models.Phrases(texts, min_count=2, threshold=10)\n",
    "\t\tbigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\t\treturn [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "\tdef lemmatization(self, texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "\t\t\"\"\"\n",
    "\t\tTokenize and lemmatize all documents. The following criteria are used to evaluate each word.\n",
    "\t\t\t\tIs the token a stop word?\n",
    "\t\t\t\tIs the token comprised of letters?\n",
    "\t\t\t\tIs the token longer than 1 letter?\n",
    "\t\t\t\tIs the token an allowed POS tag?\n",
    "\t\t\t\tIs the lemmatized token a stop word?\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"Lemmatizing Text\")\n",
    "\n",
    "\t\t# Initialize spaCy\n",
    "\t\tnlp = spacy.load('en_core_web_md', disable=[\"parser\", \"ner\"])\n",
    "\n",
    "\t\ttexts_out = []\n",
    "\n",
    "\t\tfor text in texts:\n",
    "\t\t\tdoc = nlp(text)\n",
    "\t\t\ttexts_out.append([token.lemma_ for token in doc\n",
    "\t\t\t\t\t\t\t  if not token.is_stop\n",
    "\t\t\t\t\t\t\t  and token.lemma_ not in self.stop_words\n",
    "\t\t\t\t\t\t\t  and token.is_alpha\n",
    "\t\t\t\t\t\t\t  and len(token) > 1\n",
    "\t\t\t\t\t\t\t  and token.pos_ in allowed_postags])\n",
    "\n",
    "\t\t\tif len(texts_out) % 1000 == 0:\n",
    "\t\t\t\tprint(\"Lemmatized {0} of {1} documents\".format(\n",
    "\t\t\t\t\tlen(texts_out), len(texts)))\n",
    "\n",
    "\t\treturn texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the file path to the article files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/\"\n",
    "all_files = glob.glob(file_path + \"*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all articles with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.concat((pd.read_csv(\n",
    "    f, usecols=[\"id\", \"title\", \"publication\", \"content\"]) for f in all_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first 1000 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the TF-IDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer=\"word\",\n",
    "                    ngram_range=(1, 3),\n",
    "                    min_df=2,\n",
    "                    stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_tfidf = tf.fit_transform(articles[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `mx_tfidf` to an MXNet NDArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_tfidf = mx.nd.sparse.array(mx_tfidf, ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the dot product, and create the cosine similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_recsys = mx.nd.sparse.dot(mx_tfidf, mx_tfidf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df_articles, article_idx, mx_mat, n_recs=10):\n",
    "    \"\"\"\n",
    "    Request top N article recommendations.\n",
    "\n",
    "    INPUT\n",
    "        df_articles: Pandas DataFrame containing all articles.\n",
    "        user_id: User ID being provided matches.\n",
    "        mx_mat: MXNet cosine similarity matrix\n",
    "    OUTPUT\n",
    "        Pandas DataFrame of top N article recommendations.\n",
    "    \"\"\"\n",
    "\n",
    "    # user_idx = article_idx\n",
    "\n",
    "    article_sims = mx_mat[article_idx].asnumpy()\n",
    "    article_recs = np.argsort(-article_sims)[:n_recs + 1]\n",
    "\n",
    "    # Top recommendations\n",
    "    df_recs = df_articles.loc[list(article_recs)]\n",
    "    df_recs[\"similarity\"] = article_sims[article_recs]\n",
    "\n",
    "    return df_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 recommendations from the article at index 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recs = get_recommendations(df_articles = articles,\n",
    "    article_idx = 3, mx_mat = mx_recsys, n_recs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the recommendations in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feared my life lacked meaning. Cancer pushed...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2016 Eyewitness: our summary of the defining i...</td>\n",
       "      <td>0.116453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Very hot drinks may cause cancer, but coffee d...</td>\n",
       "      <td>0.110511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Facing my fear: did I have the cancer mutation...</td>\n",
       "      <td>0.100189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Gay Talese: ‘Most journalists are voyeurs. Of ...</td>\n",
       "      <td>0.087257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>‘None of the old rules apply’: Dave Eggers tra...</td>\n",
       "      <td>0.083596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Chesley Sullenberger: an old-fashioned kind of...</td>\n",
       "      <td>0.080756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>‘It’s not about your age, it’s about your idea...</td>\n",
       "      <td>0.078553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Tragic, fascinating, brilliant – life of ‘wild...</td>\n",
       "      <td>0.078132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Transgender stories: ’People think we wake up ...</td>\n",
       "      <td>0.076837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>The reinvention of radical protest: life on th...</td>\n",
       "      <td>0.074326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  similarity\n",
       "3    I feared my life lacked meaning. Cancer pushed...    1.000000\n",
       "845  2016 Eyewitness: our summary of the defining i...    0.116453\n",
       "558  Very hot drinks may cause cancer, but coffee d...    0.110511\n",
       "374  Facing my fear: did I have the cancer mutation...    0.100189\n",
       "959  Gay Talese: ‘Most journalists are voyeurs. Of ...    0.087257\n",
       "202  ‘None of the old rules apply’: Dave Eggers tra...    0.083596\n",
       "958  Chesley Sullenberger: an old-fashioned kind of...    0.080756\n",
       "876  ‘It’s not about your age, it’s about your idea...    0.078553\n",
       "76   Tragic, fascinating, brilliant – life of ‘wild...    0.078132\n",
       "47   Transgender stories: ’People think we wake up ...    0.076837\n",
       "887  The reinvention of radical protest: life on th...    0.074326"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recs[[\"title\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
